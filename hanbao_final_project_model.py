# -*- coding: utf-8 -*-
"""HanBao_Final Project Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LGUajYwua_r25fLmca8EyDhQJzk1dK4g

### Han (Hannah) Bao
### Text Analytics
### 4/6/23
### <center> Assignment 3: Text Classification <center>
"""

#import all the packages that will be used in this lab
import matplotlib.pyplot as plt
import re
import os
import string
import pandas as pd
import numpy as np

#processing libraries
import nltk
from nltk.tokenize import word_tokenize
from nltk import PorterStemmer
from nltk import WordNetLemmatizer
from nltk.corpus import stopwords

#ML libraries
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn import metrics

import tqdm as notebook_tqdm
import torch

import gensim

!pip install vaderSentiment

#import the package
from textblob import TextBlob
#import vader
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

"""### 1.0 Load Data"""

# Load the data from the Apporto machine to the Colab environment

from google.colab import files
uploaded = files.upload()

# pandas to read spamEmail.csv
data = pd.read_csv('chatgpt_tweets.csv')
data = data.drop(columns='Unnamed: 0')
data.head()

# Check if there's any missing values
print(display(data.isna().sum()))

# Data example display
data.head()

# Show the total numbers of spam and non-spam
data[['labels']].value_counts()

# show the data type and size of the data
data.info()

# convert all review text into list format
docs = data['tweets'].tolist()
docs[1]

"""#### data preprocessing"""

# remove url
import re

def remove_url(text):
    text = re.sub(r"http\S+", "", text)
    return text

!pip install demoji

# Convert emojis
import demoji

# demoji.download_codes()

def handle_emoji(string):
    emojis = demoji.findall(string)

    for emoji in emojis:
        string = string.replace(emoji, " " + emojis[emoji].split(":")[0])

    return string

from tqdm import tqdm

#def preliminary(docs):
for i in tqdm(range(len(docs))):
    docs[i] = remove_url(docs[i])
    docs[i] = handle_emoji(docs[i])
    pass

# Remove punctuation 
punc = string.punctuation

for i in tqdm(range(len(docs))):
    docs[i] = docs[i].replace('\\n', '')
    for j in punc:
        docs[i] = docs[i].replace(j, '')
        
docs[:5]

# sentence doc
docs1 = docs.copy()

# Tokenize the documents.
from nltk.tokenize import RegexpTokenizer
from nltk.corpus import stopwords
#[0-9][a-Z]_
# Split the documents into tokens.
#w+ indicates to match at least 1 word character
tokenizer = RegexpTokenizer(r'\w+')
for idx in tqdm(range(len(docs1))):
    docs1[idx] = docs1[idx].lower()  # Convert to lowercase.
    docs1[idx] = tokenizer.tokenize(docs1[idx])  # Split into words.

docs1[0]

# remove numbers
docs1 = [[token for token in doc if not token.isnumeric()] for doc in docs1]
    
#docs1[4]

nltk.download('stopwords')

tqdm.pandas()
# 'face' is for the emoji
new_stopwords = ['chatgpt', 'ai', 'openai', 'via', 'face', 
                 'could', 'would', 'also']
list_stopwords = stopwords.words('english') + new_stopwords


# remove stopwords
def remove_stopwords(tokens):
    return [token for token in tokens if token not in list_stopwords]

docs1 = [remove_stopwords(doc) for doc in tqdm(docs1)]
#docs1

nltk.download('wordnet')

temp = docs1.copy()

# Remove words that are only one character.
temp = [[token for token in doc if len(token) > 1] for doc in temp]
#print(temp[2])

# Lemmatize the documents.

lemmatizer = WordNetLemmatizer()
temp = [[lemmatizer.lemmatize(token) for token in doc] for doc in temp]
#print(temp[2])

# use Phrases to Compute bigrams.
from gensim.models import Phrases

update_docs = temp.copy()

# Add bigrams to docs (only ones that appear 10 times or more).
bigram = Phrases(update_docs, min_count = 10)

#print(bigram[update_docs[0]])

# put the bigram (string with _) back into docs
for idx in range(len(update_docs)):
    for token in bigram[update_docs[idx]]:
        if '_' in token:
            # Token is a bigram, add to document.
            update_docs[idx].append(token)
       
    
update_docs[2][10:]

# Remove rare and common tokens.
from gensim.corpora import Dictionary

temp1 = update_docs.copy()

# Create a dictionary representation of the documents.
dictionary = Dictionary(temp1)

# Filter out words that occur less than 100 documents, or more than 80% of the documents.
# This step would be necessary in larger text
dictionary.filter_extremes(no_below=1000, no_above=0.8)

print(temp1[2])

# combine each words together for later calculation
#def list_to_sentence(words):
#    sentence = ' '.join(word for word in words if not word.isnumeric())
#    sentence = ''.join(c for c in sentence if c.isalnum() or c.isspace())
    
#    return sentence

# There are some missing values so to filter 
def list_to_sentence(words):
    if words is None:
        return None
    sentence = ' '.join(word for word in words if not word.isnumeric())
    sentence = ''.join(c for c in sentence if c.isalnum() or c.isspace())
    
    return sentence

#df_test = df_temp[['tweets','clean_tweets']].copy()
df_temp = data.copy()
df_temp['clean_tweets'] = temp1

from tqdm import tqdm
tqdm.pandas()
df_temp['clean_tweets2'] = df_temp['clean_tweets'].progress_apply(list_to_sentence)

# If count netural as good => count similar
# if count netural as bad => 163283 vs. 56011(good)
def label(y):
    if y == 'bad':
        return 0
    #elif y == 'bad':
     #   return 0
    else:
        return 1
    
from tqdm import tqdm

tqdm.pandas()

df_temp['y'] = df_temp.labels.progress_apply(label)

df_temp.head()

df_temp.to_csv('cleaned_labeled_data.csv')

"""### Sentiment Analysis

#### Splitting the dataset
"""

# Load the data from the Apporto machine to the Colab environment

from google.colab import files
uploaded = files.upload()

df_temp = pd.read_csv('cleaned_labeled_data.csv')
df_temp = df_temp.drop(columns='Unnamed: 0')
df_temp.head()

df_temp['clean_tweets2'].isna().value_counts()

def is_list(x):
    return isinstance(x, list)

# Apply the function to the column and check if any values are True
if df_temp['clean_tweets2'].apply(is_list).any():
    print('The column contains lists')

# split to 30 percent test data and 70 percent train data
# other splits of 60:40, 50:50 are also welcome

# labels are y, the dependent variable
# Messages are x, the dependent variable
train_corpus, test_corpus, train_labels, test_labels = train_test_split(df_temp["clean_tweets2"],
                                                                        df_temp["y"],
                                                                        test_size=0.3)

train_corpus

"""### 1.1: Feature representation
- binary representations
"""

# create a vector that shows whether a term represents in the message
# create an instance of countvectorizer
vectorizer = CountVectorizer(min_df=3, ngram_range=(1,1), binary=True)

# fit the vectorizer on the corpus and transform to a binary feature representation                 
binary_train_features = vectorizer.fit_transform(train_corpus)
binary_test_features = vectorizer.transform(test_corpus)

binary_train_features.toarray()

df = pd.DataFrame(binary_test_features.toarray())
df



"""- Frequency representation (BOW)"""

# build bag of words features' vectorizer and get features
bow_vectorizer = CountVectorizer(min_df=1, ngram_range=(1,1))
bow_train_features = bow_vectorizer.fit_transform(train_corpus)
bow_test_features = bow_vectorizer.transform(test_corpus)

print(bow_train_features[0])



"""- TFIDF Representation"""

# build tfidf features' vectorizer and get features
tfidf_vectorizer=TfidfVectorizer(min_df=1, 
                                 norm='l2',
                                 smooth_idf=True,
                                 use_idf=True,
                                 ngram_range=(1,1))
tfidf_train_features = tfidf_vectorizer.fit_transform(train_corpus)  
tfidf_test_features = tfidf_vectorizer.transform(test_corpus)

print(tfidf_train_features)

"""### 1.2 Modeling & Evaluation
#### Machine Learning on Binary Approach
"""

# import Classifier from libary
from sklearn.naive_bayes import MultinomialNB # import naive bayes
from sklearn.tree import DecisionTreeClassifier # import Decision Tree
from sklearn.ensemble import RandomForestClassifier # import random forest

# Print score report using self-defined function 
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score

# a function that shows evaluation metrics
def print_score(clf, train_features, train_labels, test_features, test_label, train=True):
    
    #build model
    clf.fit(train_features, train_labels)
    # predict the features
    pred = clf.predict(test_features)
    
    clf_report = pd.DataFrame(classification_report(test_labels, pred, output_dict=True))
    print("Train result: \n===============================================")
    print(f"Accuracy score: {accuracy_score(test_labels, pred) * 100:.2f}%")
    print("----------------------------------------------")
    print(f"CLASSIFICATION REPORT: \n{clf_report}")
    print("----------------------------------------------")
    print(f"Confusion Matrix: \n{confusion_matrix(test_labels, pred)}\n")
    
    return precision_score(test_labels, pred), recall_score(test_labels, pred)



"""- **Naive Bayes on binary**"""

# assign naive bayes function to a variable for bag of words
mnb = MultinomialNB()

# evaluate naive bayes
mnb_binary_precision, mnb_binary_recall = print_score(mnb, binary_train_features, train_labels, binary_test_features, test_labels)

"""- **Decision tree on Binary**"""

# assign decision tree function to an object
dt = DecisionTreeClassifier()

# evaluate decision tree
dt_binary_precision, dt_binary_recall = print_score(dt, binary_train_features, train_labels, binary_test_features, test_labels)

"""- **Random Forest on Binary**"""

# assign random forest function to an object
rf = RandomForestClassifier(criterion="entropy")

# evaluate random forest
rf_binary_precision, rf_binary_recall = print_score(rf, binary_train_features, train_labels, binary_test_features, test_labels)

"""#### ML on BOW Approach
- **Naive Bayes on BOW**
"""

# evaluate naive bayes
mnb_bow_precision, mnb_bow_recall = print_score(mnb, bow_train_features, train_labels, bow_test_features, test_labels)

"""- **Decision Tree on BOW**"""

# evaluate decision tree
dt_bow_precision, dt_bow_recall = print_score(dt, bow_train_features, train_labels, bow_test_features, test_labels)

"""- **Random Forest on BOW**"""

# evaluate random forest
rf_bow_precision, rf_bow_recall = print_score(rf, bow_train_features, train_labels, bow_test_features, test_labels)



"""### ML on TFIDF Approach
- **Naive Bayes on TFIDF**
"""

# evaluate naive bayes
mnb_tfidf_precision, mnb_tfidf_recall = print_score(mnb, tfidf_train_features, train_labels, tfidf_test_features, test_labels)

"""- **Decision tree on TFIDF**"""

# evaluate decision tree
dt_tfidf_precision, dt_tfidf_recall = print_score(dt, tfidf_train_features, train_labels, tfidf_test_features, test_labels)

"""- **Random forest on TFIDF**"""

# evaluate random forest
rf_tfidf_precision, rf_tfidf_recall = print_score(rf, tfidf_train_features, train_labels, tfidf_test_features, test_labels)

"""### Precision and Recall Score Comparison of different models on different features"""

# create a dictionary that stores all the precision information
precision_dict = {}
for m in ["mnb","dt","rf"]:
    precision_dict[m] = {}
    for f in ["binary","bow","tfidf"]:
        exec('precision_dict["{}"]["{}"] = {}_{}_precision'.format(m, f, m, f))
        
#Accuracy Matrix
pd.DataFrame(precision_dict).rename(columns={"mnb":"Naive Bayes", 
                                            "dt":"Decision Tree", 
                                            "rf":"Random Forest"}, 
                                    index={"binary":"Binary", 
                                          "bow":"Bag-of-words", 
                                          "tfidf":"TFIDF" })

# create a dictionary that stores all the recall information
recall_dict = {}
for m in ["mnb","dt","rf"]:
    recall_dict[m] = {}
    for f in ["binary","bow","tfidf"]:
        exec('recall_dict["{}"]["{}"] = {}_{}_precision'.format(m, f, m, f))
        
#Accuracy Matrix
pd.DataFrame(recall_dict).rename(columns={"mnb":"Naive Bayes", 
                                          "dt":"Decision Tree", 
                                          "rf":"Random Forest"}, 
                                 index={"binary":"Binary", 
                                        "bow":"Bag-of-words", 
                                        "tfidf":"TFIDF" })

# Conclude that using bag-of-word and decision tree will have be the optimal model

# assign it to new data



"""##To run an aspect-based sentiment analysis"""

aspects = ['chatbot', 'content', 'tool', 'resource']

# Load the data from the Apporto machine to the Colab environment

from google.colab import files
uploaded = files.upload()

df_temp.head()

#df_labeled = pd.read_csv('cleaned_labeled_data.csv')
#df_labeled.head()
df_labeled = df_temp[['clean_tweets2', 'y']].copy()

import spacy
nlp = spacy.load('en_core_web_sm')

def identify_aspect(comment):
    # Apply dependency parsing to the comment
    doc = nlp(comment)
    for token in doc:
        # If the token is a noun or adjective, check if it is related to one of the aspects
        if token.pos_ in ['NOUN', 'ADJ']:
            for aspect in aspects:
                if aspect in token.text.lower():
                    return aspect
        # If the token is a named entity, check if it is related to one of the aspects
        elif token.ent_type_:
            for aspect in aspects:
                if aspect in token.ent_type_.lower():
                    return aspect
    # If none of the tokens are related to an aspect, return None
    return None

# Identify the aspect of each comment

for comment in df_labeled['clean_tweets2']:
    aspect = identify_aspect(comment)
    if aspect:
        print(f"'{comment}' is about {aspect}.")
    else:
        print(f"Could not identify the aspect of '{comment}'.")





